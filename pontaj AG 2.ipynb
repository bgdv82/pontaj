{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "261fd86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Define file paths\n",
    "raw_file_path = \"work_data.txt\"\n",
    "cleaned_file_path = \"cleaned_chat_data.txt\"\n",
    "\n",
    "# Read all lines from the file\n",
    "with open(raw_file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Define the regex pattern for a timestamp at the start of a line\n",
    "timestamp_pattern = r\"^\\d{2}\\.\\d{2}\\.\\d{4}, \\d{2}:\\d{2}\"\n",
    "\n",
    "# 1. Find the latest date in the entire file and filter lines\n",
    "latest_date = None\n",
    "lines_with_dates = []\n",
    "\n",
    "for line in lines:\n",
    "    if re.match(timestamp_pattern, line):\n",
    "        date_str = line.split(',')[0].strip()\n",
    "        line_date = datetime.strptime(date_str, \"%d.%m.%Y\").date()\n",
    "        \n",
    "        # If we find a new, later date, reset our list of lines\n",
    "        if latest_date is None or line_date > latest_date:\n",
    "            latest_date = line_date\n",
    "            lines_with_dates = [line]\n",
    "        # If it's the same latest date, add the line\n",
    "        elif line_date == latest_date:\n",
    "            lines_with_dates.append(line)\n",
    "    else:\n",
    "        # If the line doesn't have a timestamp, it's a continuation.\n",
    "        # Add it to the most recent date's lines.\n",
    "        if lines_with_dates:\n",
    "            lines_with_dates.append(line)\n",
    "\n",
    "if not lines_with_dates:\n",
    "    print(\"No valid lines with a date/time format were found in the file.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Process the filtered lines to build the complete messages\n",
    "processed_messages = []\n",
    "current_message = \"\"\n",
    "\n",
    "for line in lines_with_dates:\n",
    "    # Check if the line starts with a timestamp\n",
    "    if re.match(timestamp_pattern, line):\n",
    "        # Save the previous message and start a new one\n",
    "        if current_message:\n",
    "            processed_messages.append(current_message.strip())\n",
    "        current_message = line.strip()\n",
    "    else:\n",
    "        # If it does not have a timestamp, it's a continuation\n",
    "        current_message +=  ' ' + line.strip()\n",
    "\n",
    "# Add the final message to the list after the loop finishes\n",
    "if current_message:\n",
    "    processed_messages.append(current_message.strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c0ac4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 9 messages for the date: 17.09.2025\n",
      "Cleaned data has been saved to 'cleaned_chat_data.txt'.\n"
     ]
    }
   ],
   "source": [
    "# Save the final, processed messages to the new file\n",
    "with open(cleaned_file_path, \"w\", encoding='utf-8') as file:\n",
    "    for message in processed_messages:\n",
    "        file.write(message + \"\\n\")\n",
    "\n",
    "print(f\"Successfully processed {len(processed_messages)} messages for the date: {latest_date.strftime('%d.%m.%Y')}\")\n",
    "print(f\"Cleaned data has been saved to '{cleaned_file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68ee15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9448a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the cleaned text file from Step 1\n",
    "cleaned_file_path = \"cleaned_chat_data.txt\"\n",
    "\n",
    "# A dictionary to store the parsed data, keyed by (name, date)\n",
    "data_dict = {}\n",
    "\n",
    "# Regex patterns for extraction\n",
    "# This pattern extracts the date, time, and the rest of the message content\n",
    "message_pattern = re.compile(r\"(\\d{2}\\.\\d{2}\\.\\d{4}),\\s+(\\d{2}:\\d{2})\\s+-\\s+(.*)\")\n",
    "\n",
    "# Define the correct list of vehicles and their regex patterns for case-insensitive matching\n",
    "vehicles = [\n",
    "    r'Iveco\\s?prelată', r'Iveco', r'Prelata', r'Prelată', r'Peugeot\\s?Expert',\n",
    "    r'Peugeot', r'Macara', r'Personală', r'Personala', r'TK', r'Renault\\s?TK'\n",
    "]\n",
    "vehicle_pattern = re.compile(r\"|\".join(vehicles), re.IGNORECASE)\n",
    "\n",
    "# Keywords for start and end times\n",
    "start_keywords = re.compile(r'Am\\.?\\s?început|Am\\.?\\s?inceput', re.IGNORECASE)\n",
    "end_keywords = re.compile(r'Am\\.?\\s?terminat', re.IGNORECASE)\n",
    "\n",
    "# Read the cleaned text file line by line\n",
    "with open(cleaned_file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Match the entire line against the message pattern\n",
    "        match = message_pattern.match(line)\n",
    "        if not match:\n",
    "            continue\n",
    "            \n",
    "        date_str, time_str, message_content = match.groups()\n",
    "        \n",
    "        # Split message_content to find the name and the rest of the message\n",
    "        # The name is the part before the first colon\n",
    "        name_end_index = message_content.find(\":\")\n",
    "        if name_end_index != -1:\n",
    "            name_str = message_content[:name_end_index].strip()\n",
    "            # The message starts after the colon and the following space\n",
    "            message_body = message_content[name_end_index+1:].strip()\n",
    "        else:\n",
    "            name_str = \"Unknown\"\n",
    "            message_body = message_content.strip()\n",
    "\n",
    "        # Extract Ora intrare and Ora iesire\n",
    "        ora_intrare = None\n",
    "        if start_keywords.search(message_body):\n",
    "            ora_intrare = time_str\n",
    "            \n",
    "        ora_iesire = None\n",
    "        if end_keywords.search(message_body):\n",
    "            ora_iesire = time_str\n",
    "            \n",
    "        # Extract Masina and Locatii\n",
    "        masina = None\n",
    "        # Remove keywords before looking for Masina, to prevent false positives\n",
    "        body_without_keywords = start_keywords.sub('', message_body)\n",
    "        body_without_keywords = end_keywords.sub('', body_without_keywords)\n",
    "\n",
    "        masina_found = False\n",
    "        # Find all vehicles in the message body\n",
    "        for m in vehicle_pattern.finditer(body_without_keywords):\n",
    "            found_vehicle = m.group(0).strip()\n",
    "            # Handle special case for 'Personala' or 'Personală'\n",
    "            if 'personal' in found_vehicle.lower():\n",
    "                try:\n",
    "                    words = message_body.split()\n",
    "                    personal_word_index = words.index(found_vehicle)\n",
    "                    # Check for word after \"Personala\"\n",
    "                    if personal_word_index + 1 < len(words):\n",
    "                        masina = f\"{found_vehicle} {words[personal_word_index + 1]}\"\n",
    "                    else:\n",
    "                        masina = found_vehicle\n",
    "                    masina_found = True\n",
    "                    break\n",
    "                except (ValueError, IndexError):\n",
    "                    pass\n",
    "            \n",
    "            # For other vehicles, just take the first one found\n",
    "            if masina is None:\n",
    "                masina = found_vehicle\n",
    "                masina_found = True\n",
    "                break\n",
    "\n",
    "        # Extract Locatii by removing masina and keywords\n",
    "        locatii = message_body\n",
    "        locatii = start_keywords.sub('', locatii)\n",
    "        locatii = end_keywords.sub('', locatii)\n",
    "        \n",
    "        # Remove the Masina text from the Locatii string\n",
    "        if masina_found and masina is not None:\n",
    "            locatii = locatii.replace(masina, '').strip()\n",
    "        \n",
    "        # Clean up remaining text in Locatii\n",
    "        locatii = re.sub(r'^\\s*[-,\\s:]+', '', locatii).strip()\n",
    "        locatii = re.sub(r'[-,\\s:]+$', '', locatii).strip()\n",
    "        if not locatii:\n",
    "            locatii = None\n",
    "\n",
    "        # Create a unique key for each person on each day\n",
    "        key = (name_str, date_str)\n",
    "        \n",
    "        # Use the key to update or create a new entry in the dictionary\n",
    "        if key not in data_dict:\n",
    "            data_dict[key] = {\n",
    "                'Numele': name_str,\n",
    "                'Data': date_str,\n",
    "                'Ora intrare': ora_intrare,\n",
    "                'Ora iesire': ora_iesire,\n",
    "                'Masina': masina,\n",
    "                'Locatii': locatii\n",
    "            }\n",
    "        else:\n",
    "            if ora_intrare:\n",
    "                data_dict[key]['Ora intrare'] = ora_intrare\n",
    "            if ora_iesire:\n",
    "                data_dict[key]['Ora iesire'] = ora_iesire\n",
    "            if masina:\n",
    "                data_dict[key]['Masina'] = masina\n",
    "            if locatii:\n",
    "                data_dict[key]['Locatii'] = locatii\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "pontaj_df = pd.DataFrame(list(data_dict.values()))\n",
    "\n",
    "# Convert string dates to datetime objects for calculation\n",
    "pontaj_df['Data'] = pd.to_datetime(pontaj_df['Data'], format='%d.%m.%Y')\n",
    "pontaj_df['Entry_Time_DT'] = pd.to_datetime(pontaj_df['Ora intrare'], format='%H:%M', errors='coerce')\n",
    "pontaj_df['Exit_Time_DT'] = pd.to_datetime(pontaj_df['Ora iesire'], format='%H:%M', errors='coerce')\n",
    "\n",
    "# Calculate Timp total de lucru\n",
    "pontaj_df['Timp total de lucru'] = (pontaj_df['Exit_Time_DT'] - pontaj_df['Entry_Time_DT']).dt.total_seconds() / 3600\n",
    "pontaj_df['Timp total de lucru'] = pontaj_df['Timp total de lucru'].round(2)\n",
    "\n",
    "# Drop intermediate columns\n",
    "final_columns = ['Numele', 'Data', 'Ora intrare', 'Ora iesire', 'Masina', 'Locatii', 'Timp total de lucru']\n",
    "pontaj_df = pontaj_df[final_columns]\n",
    "\n",
    "# Display the final DataFrame to review the result\n",
    "#print(\"Final DataFrame:\")\n",
    "# print(pontaj_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "913e62b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   Numele               8 non-null      object        \n",
      " 1   Data                 8 non-null      datetime64[ns]\n",
      " 2   Ora intrare          8 non-null      object        \n",
      " 3   Ora iesire           0 non-null      object        \n",
      " 4   Masina               3 non-null      object        \n",
      " 5   Locatii              7 non-null      object        \n",
      " 6   Timp total de lucru  0 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(5)\n",
      "memory usage: 580.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "pontaj_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "232f7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# # --- This code block assumes you have already created the 'final_df' from Step 2 ---\n",
    "\n",
    "# # Get the month and year from the 'Data' column of the DataFrame\n",
    "# # We can use the first entry since all entries are from the same day\n",
    "# if not pontaj_df.empty:\n",
    "#     latest_date_from_df = pontaj_df['Data'].iloc[0]\n",
    "    \n",
    "#     # Format the date to \"Month Year\" for the filename\n",
    "#     excel_file_name = latest_date_from_df.strftime('%B %Y.xlsx')\n",
    "    \n",
    "#     # Check if the file already exists and provide a message\n",
    "#     if os.path.exists(excel_file_name):\n",
    "#         print(f\"File '{excel_file_name}' already exists. It will be overwritten.\")\n",
    "\n",
    "#     # Save the DataFrame to an Excel file\n",
    "#     pontaj_df.to_excel(excel_file_name, index=False)\n",
    "    \n",
    "#     print(f\"DataFrame successfully saved to '{excel_file_name}'\")\n",
    "\n",
    "# else:\n",
    "#     print(\"The DataFrame is empty. No file was saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad196760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_or_create_excel(pontaj_df):\n",
    "    \"\"\"\n",
    "    Update existing Excel file with new data or create a new one if it doesn't exist\n",
    "    \n",
    "    Args:\n",
    "        pontaj_df: DataFrame containing the new data to add/update\n",
    "    \"\"\"\n",
    "    \n",
    "    if pontaj_df.empty:\n",
    "        print(\"DataFrame is empty. No file operations performed.\")\n",
    "        return\n",
    "    \n",
    "    # Get the month and year from the 'Data' column of the DataFrame\n",
    "    # We can use the first entry since all entries are from the same day\n",
    "    latest_date_from_df = pontaj_df['Data'].iloc[0]\n",
    "    \n",
    "    # Format the date to \"Month Year\" for the filename\n",
    "    excel_file_name = latest_date_from_df.strftime('%B %Y.xlsx')\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(excel_file_name):\n",
    "            print(f\"File '{excel_file_name}' already exists. Updating with new data...\")\n",
    "            \n",
    "            # Read the existing Excel file\n",
    "            existing_df = pd.read_excel(excel_file_name)\n",
    "            \n",
    "            # Check if 'Data' column exists in both DataFrames for proper merging\n",
    "            if 'Data' in existing_df.columns and 'Data' in pontaj_df.columns:\n",
    "                \n",
    "                # Convert 'Data' columns to datetime for proper comparison\n",
    "                existing_df['Data'] = pd.to_datetime(existing_df['Data'])\n",
    "                pontaj_df['Data'] = pd.to_datetime(pontaj_df['Data'])\n",
    "                \n",
    "                # Get dates that are in the new data\n",
    "                new_dates = pontaj_df['Data'].unique()\n",
    "                \n",
    "                # Remove rows from existing data that have the same dates as new data\n",
    "                # This prevents duplicates and ensures we have the latest data\n",
    "                existing_df_filtered = existing_df[~existing_df['Data'].isin(new_dates)]\n",
    "                \n",
    "                # Combine existing data (without duplicated dates) with new data\n",
    "                updated_df = pd.concat([existing_df_filtered, pontaj_df], ignore_index=True)\n",
    "                \n",
    "                # Sort by date to maintain chronological order\n",
    "                updated_df = updated_df.sort_values('Data').reset_index(drop=True)\n",
    "                \n",
    "                print(f\"Updated data: {len(existing_df_filtered)} existing records + {len(pontaj_df)} new records = {len(updated_df)} total records\")\n",
    "                \n",
    "            else:\n",
    "                # If 'Data' column doesn't exist or structure is different, append new data\n",
    "                print(\"Warning: Column structure doesn't match. Appending new data to existing file.\")\n",
    "                updated_df = pd.concat([existing_df, pontaj_df], ignore_index=True)\n",
    "            \n",
    "            # Save the updated DataFrame back to Excel\n",
    "            updated_df.to_excel(excel_file_name, index=False)\n",
    "            print(f\"✓ File '{excel_file_name}' updated successfully!\")\n",
    "            \n",
    "        else:\n",
    "            # File doesn't exist, create a new one\n",
    "            print(f\"File '{excel_file_name}' does not exist. Creating new file...\")\n",
    "            pontaj_df.to_excel(excel_file_name, index=False)\n",
    "            print(f\"✓ New file '{excel_file_name}' created successfully!\")\n",
    "            \n",
    "        # Display summary information\n",
    "        print(f\"\\nFile Details:\")\n",
    "        print(f\"  Filename: {excel_file_name}\")\n",
    "        print(f\"  Location: {os.path.abspath(excel_file_name)}\")\n",
    "        print(f\"  Records: {len(updated_df) if os.path.exists(excel_file_name) and 'updated_df' in locals() else len(pontaj_df)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Excel file: {e}\")\n",
    "        \n",
    "        # Fallback: save with timestamp to avoid data loss\n",
    "        fallback_filename = f\"pontaj_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "        pontaj_df.to_excel(fallback_filename, index=False)\n",
    "        print(f\"Data saved to fallback file: {fallback_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d8f768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'September 2025.xlsx' already exists. Updating with new data...\n",
      "Updated data: 10 existing records + 8 new records = 18 total records\n",
      "✓ File 'September 2025.xlsx' updated successfully!\n",
      "\n",
      "File Details:\n",
      "  Filename: September 2025.xlsx\n",
      "  Location: e:\\Deeplearning.ai DA\\Modulul 3 - python\\Pontaj\\September 2025.xlsx\n",
      "  Records: 18\n"
     ]
    }
   ],
   "source": [
    "if not pontaj_df.empty:\n",
    "    update_or_create_excel(pontaj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a0959a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dlpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
